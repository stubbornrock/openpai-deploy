- code: 0
  phrase: Succeeded
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_SUCCESS
  stage: COMPLETING
  behavior: UNKNOWN
  reaction: NEVER_RETRY
  repro:
    - "User program exits with exitcode 0"


- code: -100
  phrase: ConfigMapExternalDeleted
  issuer: PAI_FC
  causer: PAI_UNKNOWN
  type: PLATFORM_FAILURE
  stage: UNKNOWN
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "The ConfigMap of this job attempt is deleted by external unexpectedly"
  repro:
    - "Manually delete the ConfigMap of this job attempt"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: -101
  phrase: PodExternalDeleted
  issuer: PAI_FC
  causer: PAI_UNKNOWN
  type: PLATFORM_FAILURE
  stage: UNKNOWN
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod is deleted by external unexpectedly"
  repro:
    - "Manually delete a Pod of this job"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: -110
  phrase: ConfigMapCreationTimeout
  issuer: PAI_FC
  causer: PAI_UNKNOWN
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "The ConfigMap of this job attempt creation timeout, maybe K8S ApiServer is down"
  repro:
    - "Just after FC created a ConfigMap, bring down the K8S ApiServer"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: -111
  phrase: PodCreationTimeout
  issuer: PAI_FC
  causer: PAI_UNKNOWN
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod creation timeout, maybe K8S ApiServer is down"
  repro:
    - "Just after FC created a Pod, bring down the K8S ApiServer"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: -200
  phrase: PodSpecPermanentError
  issuer: PAI_FC
  causer: USER_SUBMISSION
  type: USER_FAILURE
  stage: SUBMITTING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Pod spec contains permanent error"
  repro:
    - "Specify a Pod in Framework with duplicated container names"
  solution:
    - "Check diagnostics and revise your job config"


- code: -210
  phrase: StopFrameworkRequested
  issuer: PAI_FC
  causer: USER_STOP
  type: USER_STOP
  stage: UNKNOWN
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "User has requested to stop the job"
  repro:
    - "Stop a job"


- code: -220
  phrase: FrameworkAttemptCompletion
  issuer: PAI_FC
  causer: USER_STOP
  type: USER_STOP
  stage: UNKNOWN
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Stop to complete current FrameworkAttempt"
  repro:
    - "Stop a job with long running container"

- code: -300
  phrase: PodFailedWithoutFailedContainer
  issuer: PAI_FC
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: LAUNCHING
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "Pod failed but without any failed container, may be stopped by K8S"
  repro:
    - "Submit a job which will be rejected by kubelet"
  solution:
    - "Check diagnostics and find root cause"
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: -1000
  phrase: PodEvicted
  issuer: PAI_K8S
  causer: PAI_K8S
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod is evicted by K8S, maybe its node is out of resource"
  repro:
    - "Start a raw process on the host to use up almost all memory on the node"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^Evicted$'
      messageRegex: '(?ms).*'


- code: -1001
  phrase: PodNodeLost
  issuer: PAI_K8S
  causer: PAI_K8S
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod lost due to node lost, maybe its kubelet is down for a long time"
  repro:
    - "Stop the Pod's kubelet"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^NodeLost$'
      messageRegex: '(?ms).*'


- code: -1002
  phrase: PodScheduledToInsufficientResourceNode
  issuer: PAI_K8S
  causer: PAI_K8S
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod is rejected by the kubelet of its node, because it is wrongly scheduled to a node with insufficient required resource"
  repro:
    - "Directly bind a Pod to a node with more required memory than the node capacity"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^OutOf\S+$'
      messageRegex: '(?ms).*'


- code: -1003
  phrase: PodPreemptedForCriticalPod
  issuer: PAI_K8S
  causer: PAI_K8S
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod is preempted by the kubelet of its node for the admission of other more critical platform Pod"
  repro:
    - "Submit a large critical Pod to a node with a normal Pod already running"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^Preempting$'
      messageRegex: '(?ms).*'

- code: -1004
  phrase: PodDeadlineExceeded
  issuer: PAI_K8S
  causer: USER_STOP
  type: USER_STOP
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Pod is stopped by the kubelet of its node, because its specified deadline exceeded"
  repro:
    - "Submit a large critical Pod to a node with a normal Pod already running"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^DeadlineExceeded$'
      messageRegex: '(?ms).*'


- code: -1005
  phrase: PodNodeAdmissionForbidden
  issuer: PAI_K8S
  causer: USER_SUBMISSION
  type: USER_FAILURE
  stage: LAUNCHING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Pod is forbidden by the kubelet of its node, maybe it is invalid"
  repro:
    - "Submit a privileged Pod to a node which does not allow privileged container"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^Forbidden$'
      messageRegex: '(?ms).*'


- code: -1006
  phrase: PodNodeAdmissionUnexpectedError
  issuer: PAI_K8S
  causer: PAI_K8S
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Pod is rejected by the kubelet due to unexpected error"
  repro:
    - "Transient errors in kubelet"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      reasonRegex: '(?i)^UnexpectedAdmissionError$'
      messageRegex: '(?ms).*'
    -
      reasonRegex: '(?i)^UnknownReason$'
      messageRegex: '(?ms).*'
    -
      reasonRegex: '(?i)^InvalidNodeInfo$'
      messageRegex: '(?ms).*'
    -
      reasonRegex: '(?i)^UnexpectedPredicateFailureType$'
      messageRegex: '(?ms).*'


- code: -1300
  phrase: InitContainerDockerOOMKilled
  issuer: PAI_DOCKER
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Init Container killed by docker due to it exceeded the request memory"
  repro:
    - "Init Container uses more memory than its requested"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?i)^init$'
        reasonRegex: '(?i)^OOMKilled$'
        messageRegex: '(?ms).*'


- code: -1200
  phrase: UserContainerDockerOOMKilled
  issuer: PAI_DOCKER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "User Container killed by docker due to it exceeded the request memory"
  repro:
    - "User program uses more memory than its requested"
  solution:
    - "Increase per task memory request"
    - "Decrease per task memory usage by such as increasing task number"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^OOMKilled$'
        messageRegex: '(?ms).*'


- code: -1201
  phrase: ContainerDockerCreationError
  issuer: PAI_DOCKER
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: LAUNCHING
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "Failed to create docker container"
  repro:
    - "Execute docker run with image foo123"
  solution:
    - "Check diagnostics and find root cause"
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?ms).*'
        exitCode: 125


- code: -1202
  phrase: ContainerDockerStartCmdPermissionDenied
  issuer: PAI_DOCKER
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Failed to start docker container due to permission denied"
  repro:
    - "Execute docker run with cmd /etc"
  solution:
    - "Contact PAI Dev to fix the PAI Runtime bug"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?ms).*'
        exitCode: 126


- code: -1203
  phrase: ContainerDockerStartCmdNotFound
  issuer: PAI_DOCKER
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Failed to start docker container due to cmd not found"
  repro:
    - "Execute docker run with cmd foo"
  solution:
    - "Contact PAI Dev to fix the PAI Runtime bug"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?ms).*'
        exitCode: 127
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?msi).*(not found|cannot find|no such).*'
        exitCode: 128

- code: -1204
  phrase: ContainerDockerStartUnknownError
  issuer: PAI_DOCKER
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: LAUNCHING
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "Failed to start docker container due to unknown error"
  repro:
    - "Submit a Pod with unknown capability specified in its SecurityContext"
  solution:
    - "Check diagnostics and find root cause"
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?ms).*'
        exitCode: 128


- code: -1205
  phrase: ContainerGpuDeviceNotFoundError
  issuer: PAI_DOCKER
  causer: PAI_HW
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container failed due to the allocated GPU device is not found on node"
  repro:
    - "Run tensorflow on GPU index 3 while the node only has 3 GPUs"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    controllerPodPatterns:
    -
      containers:
      -
        nameRegex: '(?ms).*'
        reasonRegex: '(?i)^ContainerCannotRun$'
        messageRegex: '(?msi).*(nvidia-container-cli: device error: unknown device id).*'
        exitCode: 128


- code: 130
  phrase: ContainerSigIntReceived
  issuer: PAI_OS
  causer: PAI_OS
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container killed by OS Signal: SIGINT"
  repro:
    - "Kill container process by SIGINT"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 130


- code: 131
  phrase: ContainerSigQuitReceived
  issuer: PAI_OS
  causer: PAI_OS
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container killed by OS Signal: SIGQUIT"
  repro:
    - "Kill container process by SIGQUIT"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 131


- code: 132
  phrase: ContainerSigIllReceived
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container killed by OS Signal: SIGILL"
  repro:
    - "User program executes an illegal, malformed, unknown, or privileged machine instruction"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 132


- code: 134
  phrase: ContainerSigAbrtReceived
  issuer: USER_CONTAINER
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: RUNNING
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "Container killed by OS Signal: SIGABRT"
  repro:
    - "User program calls abort() by libc"
  solution:
    - "Check container log and find root cause"
    - "Wait result from next retry"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 134


- code: 135
  phrase: ContainerSigBusReceived
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container killed by OS Signal: SIGBUS"
  repro:
    - "User program accesses an unaligned memory address"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 135


- code: 136
  phrase: ContainerSigFpeReceived
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container killed by OS Signal: SIGFPE"
  repro:
    - "User program division by zero"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 136


- code: 137
  phrase: ContainerSigKillReceived
  issuer: PAI_OS
  causer: PAI_OS
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container killed by OS Signal: SIGKILL"
  repro:
    - "Kill container process by SIGKILL"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 137
- code: 139
  phrase: ContainerSigSegvReceived
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container killed by OS Signal: SIGSEGV"
  repro:
    - "User program accesses an illegal memory address"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 139


- code: 141
  phrase: ContainerSigPipeReceived
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container killed by OS Signal: SIGPIPE"
  repro:
    - "User program writes to a pipe without a process connected to the other end"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 141


- code: 143
  phrase: ContainerSigTermReceived
  issuer: PAI_OS
  causer: PAI_OS
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container killed by OS Signal: SIGTERM"
  repro:
    - "Kill container process by SIGTERM"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 143


- code: 220
  phrase: UserCommandExitWithError
  issuer: USER_CONTAINER
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "User command is invalid"
  repro:
    - "Start a job with invalid command"
  solution:
    - "Check the user command"
    - "Check the PATH environment variable in the container"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 127
      userLogRegex: '(?i)command not found'


- code: 221
  phrase: ContainerTensorflowOOMKilled
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Tensorflow failed due to out of memory"
  repro:
    - "Tensorflow uses more memory than it is allocated"
  solution:
    - "Increase per task memory request"
    - "Decrease per task memory usage by such as increasing task number"
    - "Tuning the tensorflow program"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?msi)tensorflow.*ResourceExhaustedError.*OOM.*'
    -
      userLogRegex: '(?i)ran out of memory trying to allocate'


- code: 222
  phrase: ContainerMPISegvFault
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "MPI failed due to memory segmentation fault"
  repro:
    - "MPI accesses unmapped memory region"
  solution:
    - "Check container log and fix your program bug"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?msi)Signal code: Address not mapped.*'


- code: 223
  phrase: ContainerCudaUncorrectableECCError
  issuer: PAI_RUNTIME
  causer: PAI_HW
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Container failed due to GPU uncorrectable ECC error"
  repro:
    - "Run tensorflow on a GPU which has ECC error"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?msi)CUDA_ERROR_ECC_UNCORRECTABLE.*'


- code: 224
  phrase: ContainerCudaVersionMismatch
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to cude version mismatch"
  repro:
    - "Using cude 10 in container with driver version below 410.48"
  solution:
    - "Change docker image with correct cuda runtime version"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)cuda driver version is insufficient for cuda runtime version'


- code: 225
  phrase: ContainerCudaDnnVersionMismatch
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to cuda dnn version mismatch"
  repro:
    - "Running latest pytorch with old cuDNN lib"
  solution:
    - "Change docker image with correct DL framework version"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)dropout supported only in cudnn v'


- code: 226
  phrase: ContainerCudaOOMKilled
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to out of gpu memory"
  repro:
    - "Allocate GPU memory exceed hardware limit"
  solution:
    - "Select GPU type which has more physical memory"
    - "Tuning the program parameter to use less memory"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)cuda runtime error (2) : out of memory'


- code: 227
  phrase: ContainerMayFailDueToGpuDeviceEccError
  issuer: PAI_RUNTIME
  causer: PAI_HW
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: TRANSIENT
  reaction: RETRY_TO_MAX
  reason: "Container failed may due to GPU ecc error"
  repro:
    - "Run program in GPU with ECC error"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"
  pattern:
    runtimeContainerPatterns:
    -


- code: 228
  phrase: ContainerIncorrectParameterError
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to incorrect parameter"
  repro:
    - "Call tensorflow lib with incorrect parameters"
  solution:
    - "Correct the user code"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)unknown option'
    -
      userLogRegex: '(?i)typeerror: dynamic_rnn() got multiple values for keyword argument'
    -
      userLogRegex: '(?msi)bad argument #2 to .*'
    -
      userLogRegex: '(?i)invalid argument:'
    -
      userLogRegex: '(?i)option -start_symbol has no default value'

- code: 229
  phrase: ContainerIncorrectDataModelError
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to incorrect data model"
  repro:
    - "Call DL framework lib with incorrect data model format"
  solution:
    - "Correct the user code, use correct data model"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)perhaps your file is in a different file format'
    -
      userLogRegex: '(?i)bash: bd5/bd5_bar-train.ids'
    -
      userLogRegex: '(?i)exception occurred: error opening file'
    -
      userLogRegex: '(?i)filenotfounderror: [errno 2] no such file or directory'
    -
      userLogRegex: '(?i)unicodeencodeerror:'
    -
      userLogRegex: '(?i)unicodedecodeerror'
    -
      userLogRegex: '(?i)exception: unknown text header name'
    -
      userLogRegex: '(?i)exception: unknown label header name'
    -
      userLogRegex: '(?i)eoferror: ran out of input'
    -
      userLogRegex: '(?msi)utils.lua:.*input/output error'
    -
      userLogRegex: '(?msi)tensorflow.python.framework.errors.unknownerror:.*input/output error'
    -
      userLogRegex: '(?msi)oserror:.*input/output error'
    -
      userLogRegex: '(?msi)cp: failed to close.*input/output error'
    -
      userLogRegex: '(?msi)exception occurred:.* Input/output error'


- code: 230
  phrase: ContainerInvalidSavePath
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to invalid save path"
  repro:
    - "Use invalid save path to save model"
  solution:
    - "Check the save path and correct it"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)ValueError: Restore called with invalid save path'


- code: 231
  phrase: ContainerSyntaxError
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to syntax error"
  repro:
    - "User use invalid syntax in code"
  solution:
    - "Check the source code and correct the errors"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)syntaxerror: invalid syntax'
    -
      userLogRegex: '(?i)unpicklingerror'
    -
      userLogRegex: '(?i)assign requires shapes of both tensors to match'
    -
      userLogRegex: '(?msi)torch/install/share/lua.*c.* exception'
    -
      userLogRegex: '(?msi)attributeerror:.*has no attribute'
    -
      userLogRegex: '(?msi)nameerror: name.* is not defined'


- code: 232
  phrase: ContainerImportError
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to error import"
  repro:
    - "User import invalid module"
  solution:
    - "Check the source code and correct it"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?msi)importerror:.*'


- code: 233
  phrase: ContainerIndexOutOfRange
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "User code access element which out of range"
  repro:
    - "Access element out of range"
  solution:
    - "Check the source code and correct it"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?msi)indexerror:.*index out of range'


- code: 234
  phrase: ContainerSigvFault
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to segmentation fault"
  repro:
    - "Access invalid memory address"
  solution:
    - "Correct the user code"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)segmentation fault'


- code: 235
  phrase: ContainerEngineCoreDump
  issuer: PAI_RUNTIME
  causer: USER_CONTAINER
  type: USER_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Container failed due to engine core dump"
  repro:
    - "Access invalid memory address"
  solution:
    - "Correct the user code"
  pattern:
    runtimeContainerPatterns:
    -
      userLogRegex: '(?i)core dumped'


- code: 249
  phrase: PAIRuntimeSSHBarrierTimeout
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: RUNNING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "SSH barrier reaches max retry count"
  repro:
    - "SSH barrier reaches max retry count, please check if SSH plugin is correctly configured"
  solution:
    - "Check job config to confirm all SSH barrier relied task roles enabled SSH"
  pattern:
    runtimeContainerPatterns:
    -
      exitCode: 10
      platformLogRegex: 'SSH barrier reaches max retry count'


- code: 250
  phrase: FrameworkBarrierTransientFailed
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "The FrameworkBarrier failed due to transient error"
  solution:
    - "Wait result from next retry"
    - "Contact Cluster Admin"


- code: 251
  phrase: JobGangAllocationTimeout
  issuer: PAI_RUNTIME
  causer: RESOURCE_ALLOCATION_TIMEOUT
  type: RESOURCE_ALLOCATION_TIMEOUT
  stage: ALLOCATING
  behavior: TRANSIENT_CONFLICT
  reaction: ALWAYS_BACKOFF_RETRY
  reason: "All requested resources of all tasks in the job cannot be satisfied in time"
  repro:
    - "Request more containers in a guaranteed job than its virtual cluster current available"
  solution:
    - "Wait result from next retry"
    - "Decrease task number"
    - "Decrease per task resource request"
    - "Contact Cluster Admin to increase your virtual cluster quota"


- code: 252
  phrase: FrameworkBarrierPermanentFailed
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "The FrameworkBarrier failed due to permanent error"
  repro:
    - "Run FrameworkBarrier with BARRIER_CHECK_TIMEOUT_SEC equals to 1"
  solution:
    - "Contact PAI Dev to fix the PAI Runtime bug"


- code: 253
  phrase: ContainerPortConflict
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: LAUNCHING
  behavior: TRANSIENT
  reaction: ALWAYS_RETRY
  reason: "Can not alloc request ports due to ports is occupied"
  repro:
    - "Run task in a host which most of ports are occupied"
  solution:
    - "Wait result from next retry"
    - "Decrease per task ports request"


- code: 254
  phrase: ContainerImageNotExists
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: USER_FAILURE
  stage: LAUNCHING
  behavior: PERMANENT
  reaction: NEVER_RETRY
  reason: "Pull access denied, repository does not exist or may require authentication"
  repro:
    - "Submit job with incorrect docker image uri"
  solution:
    - "Correct docker image uri in job protocol"


- code: 255
  phrase: PAIRuntimeUnknownFailed
  issuer: PAI_RUNTIME
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: UNKNOWN
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "User command failed but the failure cannot be recognized by PAI Runtime"
  repro:
    - "User program directly exits with exitcode 1"
  solution:
    - "Check container log and find root cause"
    - "Wait result from next retry"


- code: -8000
  phrase: ContainerUndefinedNegativeExitCode
  issuer: UNKNOWN
  causer: UNKNOWN
  type: UNKNOWN_FAILURE
  stage: UNKNOWN
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "Container exited with undefined negative exitcode"
  repro:
    - "Remove code -100 in the spec, then repro -100"
  solution:
    - "Contact PAI Dev to recognize this exitcode"


- code: 256
  phrase: PAIRuntimeExitAbnormally
  issuer: PAI_RUNTIME
  causer: PAI_RUNTIME
  type: PLATFORM_FAILURE
  stage: UNKNOWN
  behavior: UNKNOWN
  reaction: RETRY_TO_MAX
  reason: "PAI Runtime exit abnormally with undefined exitcode, it may have bugs"
  repro:
    - "PAI Runtime exits with exitcode 1"
  solution:
    - "Contact PAI Dev to fix PAI Runtime bugs"
